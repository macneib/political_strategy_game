# ğŸ› ï¸ Development Guide

## ğŸš€ Contributing to Political Strategy Game

This project represents a revolutionary approach to AI-driven software development, achieving production-quality results through GitHub Copilot + Claude Sonnet 4 + Beast Mode 4.1 protocols.

---

## ğŸ“‹ Development Setup

### 1. Environment Setup
```bash
# Clone and setup
git clone [your-repo-url]
cd political_strategy_game/political_strategy_game
bash setup_uv.sh

# Verify installation
python version_check.py --check
```

### 2. Project Structure Understanding
```
political_strategy_game/
â”œâ”€â”€ src/core/           # Core political simulation engine
â”œâ”€â”€ src/interactive/    # Real-time gameplay systems
â”œâ”€â”€ src/llm/           # AI integration layer
â”œâ”€â”€ demos/             # Demonstration scripts
â”œâ”€â”€ tests/             # Comprehensive test suite (391 tests)
â”œâ”€â”€ config/            # Configuration management
â””â”€â”€ validation/        # Quality assurance tools
```

---

## ğŸ¯ Development Workflow

### Testing Strategy
```bash
# Run all tests (391 comprehensive tests)
uv run python -m pytest tests/ -v

# Run specific test categories
uv run python -m pytest tests/test_core_structures.py -v    # Core systems
uv run python -m pytest tests/interactive/ -v              # Interactive features  
uv run python -m pytest tests/test_conspiracy.py -v        # Advanced politics

# Quick validation
python version_check.py --check
```

### Code Quality Standards
- **Architecture**: Modular design with clear separation of concerns
- **Testing**: 391 comprehensive tests covering all major functionality
- **Documentation**: Extensive inline documentation and architectural guides
- **AI Integration**: LLM-first design with proper context management

---

## ğŸ“¦ Version Management

### Semantic Versioning (Current: 0.8.0)
- **Major** (1.0.0): Production release with complete feature set
- **Minor** (0.9.0): LLM integration completion, game engine features
- **Patch** (0.8.1): Bug fixes and minor enhancements

### Conventional Commits
```bash
# Feature additions
git commit -m "feat(core): add strategic advisor memory evolution"
git commit -m "feat(interactive): implement real-time council voting"

# Bug fixes
git commit -m "fix(llm): resolve context window management"
git commit -m "fix(tests): update advisor relationship validation"

# Documentation
git commit -m "docs(readme): update development workflow"
git commit -m "docs(api): add LLM integration examples"
```

### Automated Releases
The project uses automated semantic release workflows:
1. Commit with conventional format
2. Push to main branch
3. GitHub Actions analyzes commits
4. Automatically bumps version and creates release
5. Generates changelog from commits

---

## ğŸ—ï¸ Architecture Guidelines

### Core Principles
1. **Modularity**: Each system should be independently testable
2. **Scalability**: Design for complexity growth and feature expansion
3. **AI-First**: LLM integration as core architectural consideration
4. **Testability**: All functionality must be comprehensively tested

### Key Systems
- **Advisor System**: AI personalities with memory and relationships
- **Political Engine**: Decision-making with reputation tracking
- **Interactive Layer**: Real-time gameplay with player intervention
- **Memory Management**: Persistent state with emotional weighting
- **LLM Integration**: Context-aware conversations and decision support

---

## ğŸ§ª Testing Philosophy

### Test Coverage Strategy
- **Unit Tests**: Individual component validation (core systems)
- **Integration Tests**: Cross-system interaction validation
- **Interactive Tests**: Real-time gameplay scenario validation
- **AI Tests**: LLM response quality and context management

### Quality Gates
- All tests must pass before merge
- New features require corresponding tests
- Performance benchmarks for AI operations
- Memory usage validation for long-running simulations

### Running Specific Test Suites
```bash
# Core functionality
uv run python tests/test_core_structures.py

# Advanced political features
uv run python tests/test_conspiracy_comprehensive.py
uv run python tests/test_diplomatic_negotiations.py

# Interactive gameplay
uv run python tests/interactive/test_real_time_council.py

# LLM integration validation
uv run python validation/validate_ai_dynamics_enhanced.py
```

---

## ğŸ”¬ AI Development Methodology

### Revolutionary Approach
This project proves that AI-driven development can achieve:
- **Production Quality**: 391 passing tests, robust architecture
- **Rapid Development**: Complex systems built with AI assistance
- **Innovation**: Novel gameplay mechanics and AI integration patterns

### AI Tools Integration
- **GitHub Copilot**: Code completion and pattern recognition
- **Claude Sonnet 4**: Architecture design and problem solving
- **Beast Mode 4.1**: Autonomous development protocols

### Best Practices
1. **Context Management**: Maintain conversation context across development sessions
2. **Iterative Refinement**: Continuous improvement through AI feedback
3. **Validation Focus**: AI-generated code with comprehensive testing
4. **Documentation**: AI-assisted documentation that evolves with code

---

## ğŸ® Feature Development Guide

### Adding New Advisor Capabilities
1. Update `src/core/advisor.py` with new personality traits
2. Add corresponding memory management in `src/core/memory.py`
3. Create tests in `tests/test_advisor_enhanced.py`
4. Update interactive layer for player access

### Implementing New Political Mechanics
1. Design in `src/core/political_entities.py`
2. Add decision tracking in reputation system
3. Create interactive interface components
4. Validate with comprehensive test scenarios

### LLM Integration Extensions
1. Update context templates in `src/llm/dialogue.py`
2. Add provider support in `src/llm/llm_providers.py`
3. Validate response quality with test scenarios
4. Document integration patterns

---

## ğŸ“ˆ Performance Considerations

### Memory Management
- Advisor memories with decay mechanisms
- LLM context window optimization
- Efficient state serialization for long games

### Scalability Targets
- Support for 50+ advisors in complex civilizations
- Real-time responsiveness for interactive features
- Efficient batch processing for AI operations

---

## ğŸ¯ Roadmap to v1.0.0

### Current Status (v0.8.0)
- âœ… Core political simulation engine
- âœ… Advanced advisor AI system
- âœ… Interactive gameplay framework
- âœ… Comprehensive testing suite

### Next Milestone (v0.9.0)
- ğŸ¯ Complete LLM integration
- ğŸ¯ Game engine optimization
- ğŸ¯ Performance benchmarking
- ğŸ¯ Production deployment preparation

### Production Release (v1.0.0)
- ğŸ† Full feature completeness
- ğŸ† Production deployment ready
- ğŸ† Comprehensive documentation
- ğŸ† Community contribution guidelines

---

## ğŸ¤ Contributing Guidelines

### Before Contributing
1. Read this development guide thoroughly
2. Run `python version_check.py --check` to understand current state
3. Examine test suite to understand expected functionality
4. Review architectural documentation in `docs/`

### Contribution Process
1. Fork repository and create feature branch
2. Develop with conventional commit messages
3. Ensure all tests pass: `uv run python -m pytest tests/ -v`
4. Update documentation as needed
5. Submit pull request with clear description

### Code Review Criteria
- All tests must pass
- Code follows project architectural patterns
- New features include corresponding tests
- Documentation updated for user-facing changes
- Performance implications considered

---

*This project demonstrates the future of software development: human creativity enhanced by AI capabilities, achieving production-quality results through innovative collaboration.*
